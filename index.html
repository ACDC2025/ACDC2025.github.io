<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ACDC</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span class="ACDC">ACDC</span>: Autoregressive Coherent Multimodal Generation using Diffusion Correction</h1>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autoregressive models (ARMs) and diffusion models (DMs) represent two leading paradigms in generative modeling, each excelling in distinct areas: ARMs in global context modeling and long-sequence generation, and DMs in generating high-quality local contexts, especially for continuous data such as images and short videos. However, ARMs often suffer from exponential error accumulation over long sequences, leading to physically implausible results, while DMs are limited by their local context generation capabilities. In this work, we introduce Autoregressive Coherent multimodal generation with Diffusion Correction (ACDC), a zero-shot approach that combines the strengths of both ARMs and DMs at the inference stage without the need for additional fine-tuning. ACDC leverages ARMs for global context generation and memory-conditioned DMs for local correction, ensuring high-quality outputs by correcting artifacts in generated multimodal tokens. In particular, we propose a memory module based on large language models (LLMs) that dynamically adjusts the conditioning texts for the DMs, preserving crucial global context information. Our experiments on multimodal tasks, including coherent multi-frame story generation and autoregressive video generation, demonstrate that ACDC effectively mitigates the accumulation of errors and significantly enhances the quality of generated outputs, achieving superior performance while remaining agnostic to specific ARM and DM architectures.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-sixths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <img src="static/images/method.png" alt="rs_algorithm"/>
          <p style=" font-size:18px;">
            In CFG++, the renoising process after applying Tweedie’s formula should utilize the unconditional noise 
            <span class="eps_null">$ \hat\epsilon_\varnothing $</span> instead of <span class="eps_cfg">$ \hat\epsilon^w_c $</span>. This surprisingly simple fix to the original CFG algorithm 
            leads to smoother trajectory of generation. This improvement is also demonstrated in the following visualization of the discrete evolution of the posterior mean.
          </p>
          <img src="static/images/tweedie_progression.png" alt="tweedie_progression"/>
        </div>
      </div>
    </div
  </div>
</section>
<!-- End Method -->

<!-- Downstream Tasks -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-sixths">
        <h2 class="title is-3">Experimental Results</h2>

        <h2 class="title is-4">1. Story Generation</h2>
        <div class="content has-text-justified" style="margin-top:-15px; margin-bottom: 30px;">
          <img src="static/images/T2I_gen_w_interpolation.png" alt="t2i_gen_w_interpolation"/>
          <p style="margin-top:5px; margin-bottom: 10px; font-size:18px;">
            As demonstrated by the teaser images, our CFG++ method results in a smoother generation trajectory and superior quality.
            Additionally, we visualize multiple images generated by CFG++ as we increase the guidance scale $ \gamma $.
            The visualization shows a smooth transition from unconditional sampling towards highly conditional sampling. 
          </p>
        </div>

        <div class="content has-text-justified" style="margin-top:-15px; margin-bottom: 30px;">
          <img src="static/images/T2I_gen_lightning.png" alt="T2I_gen_lightning"/>
          <p style="margin-top:5px; margin-bottom: 10px; font-size:18px;">
            We find that the improvement gain from CFG++ is even more dramatic for distilled diffusion models such as SDXL-{turbo, lightning}.
            We see significant boosts in the quality of the generated images, which is also depicted in the improvements seen in the above figure.
          </p>
        </div>
        
        <h2 class="title is-4"> 2. Correcting physical errors through user constraints </h2>
        <div class="content has-text-justified" style="margin-top:-15px; margin-bottom: 30px;">
          <img src="static/images/physical.png" alt="physics" style="margin-bottom:20px">
          <p style="margin-top:5px; margin-bottom: 30px; font-size: 18px;">
            In our approach, we addressed the issue of physically incorrect images generated by the base ARM model by applying Stable Diffusion (SD) inpainting for correction. This method prevents the same physical errors from quickly propagating during subsequent frame. 
            Our findings demonstrate that ACDC effectively mitigates the propagation of physical errors through this correction process.
          </p>
        </div>

        <div class="content has-text-justified" style="margin-bottom: 30px;">
          <img src="static/images/inversion_n_editing_overview.png" alt="t2i_gen_w_interpolation"/>
          <p style="margin-top:5px; font-size: 18px;">
            The figures above compare image editing results using CFG and CFG++ followed by image inversion. 
            During the editing stage, a word in the source text is swapped with the target concept, and this modified text 
            is used as the condition for sampling. Our algorithm successfully works for both synthetic and real images.
          </p>
        </div>
        
        <h2 class="title is-4">3. Autoregressive Video Generation</h2>
        <div class="content has-text-justified">
          <!-- Video Grid -->
          <div class="columns is-multiline is-centered">
            
            <!-- First Row: Prompt 1 -->
            <div class="column is-half">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">LWM</p>
            </div>

            <div class="column is-half">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3_c.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">Baseline</p>
            </div>

            <div class="column is-full">
              <p><strong>Prompt 1:</strong> Description of Prompt 1 goes here.</p>
            </div>

            <!-- Second Row: Prompt 2 -->
            <div class="column is-half">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">Ours</p>
            </div>

            <div class="column is-half">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">Baseline</p>
            </div>

            <div class="column is-full">
              <p><strong>Prompt 2:</strong> Description of Prompt 2 goes here.</p>
            </div>

            <!-- Third Row: Prompt 3 -->
            <div class="column is-half">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">Ours</p>
            </div>

            <div class="column is-half">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">Baseline</p>
            </div>

            <div class="column is-full">
              <p><strong>Prompt 3:</strong> Description of Prompt 3 goes here.</p>
            </div>

            <!-- Add more prompts and videos as necessary -->

          </div>
          <!-- End Video Grid -->

          <p style="margin-top:5px; margin-bottom: 10px; font-size: 18px;">
            These videos showcase the comparison between our approach and the baseline in generating coherent multi-frame sequences.
          </p>
      </div> 

      </div>
    </div>
  </div>
</section>



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
