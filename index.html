<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ACDC</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span class="ACDC">ACDC</span>: Autoregressive Coherent Multimodal Generation using Diffusion Correction</h1>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autoregressive models (ARMs) and diffusion models (DMs) represent two leading paradigms in generative modeling, each excelling in distinct areas: ARMs in global context modeling and long-sequence generation, and DMs in generating high-quality local contexts, especially for continuous data such as images and short videos. However, ARMs often suffer from exponential error accumulation over long sequences, leading to physically implausible results, while DMs are limited by their local context generation capabilities. In this work, we introduce Autoregressive Coherent multimodal generation with Diffusion Correction (ACDC), a zero-shot approach that combines the strengths of both ARMs and DMs at the inference stage without the need for additional fine-tuning. ACDC leverages ARMs for global context generation and memory-conditioned DMs for local correction, ensuring high-quality outputs by correcting artifacts in generated multimodal tokens. In particular, we propose a memory module based on large language models (LLMs) that dynamically adjusts the conditioning texts for the DMs, preserving crucial global context information. Our experiments on multimodal tasks, including coherent multi-frame story generation and autoregressive video generation, demonstrate that ACDC effectively mitigates the accumulation of errors and significantly enhances the quality of generated outputs, achieving superior performance while remaining agnostic to specific ARM and DM architectures.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-sixths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <img src="static/images/method.png" alt="rs_algorithm"/>
          <p style=" font-size:18px;">
            In CFG++, the renoising process after applying Tweedieâ€™s formula should utilize the unconditional noise 
            <span class="eps_null">$ \hat\epsilon_\varnothing $</span> instead of <span class="eps_cfg">$ \hat\epsilon^w_c $</span>. This surprisingly simple fix to the original CFG algorithm 
            leads to smoother trajectory of generation. This improvement is also demonstrated in the following visualization of the discrete evolution of the posterior mean.
          </p>
          <img src="static/images/tweedie_progression.png" alt="tweedie_progression"/>
        </div>
      </div>
    </div
  </div>
</section>
<!-- End Method -->

<!-- Downstream Tasks -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-sixths">
        <h2 class="title is-3">Experimental Results</h2>

        <h2 class="title is-4">1. Story Generation</h2>
        <div class="content has-text-justified" style="margin-top:-15px; margin-bottom: 30px;">
          <img src="static/images/T2I_gen_w_interpolation.png" alt="t2i_gen_w_interpolation"/>
          <p style="margin-top:5px; margin-bottom: 10px; font-size:18px;">
            As demonstrated by the teaser images, our CFG++ method results in a smoother generation trajectory and superior quality.
            Additionally, we visualize multiple images generated by CFG++ as we increase the guidance scale $ \gamma $.
            The visualization shows a smooth transition from unconditional sampling towards highly conditional sampling. 
          </p>
        </div>

        <div class="content has-text-justified" style="margin-top:-15px; margin-bottom: 30px;">
          <img src="static/images/T2I_gen_lightning.png" alt="T2I_gen_lightning"/>
          <p style="margin-top:5px; margin-bottom: 10px; font-size:18px;">
            We find that the improvement gain from CFG++ is even more dramatic for distilled diffusion models such as SDXL-{turbo, lightning}.
            We see significant boosts in the quality of the generated images, which is also depicted in the improvements seen in the above figure.
          </p>
        </div>
        
        <h2 class="title is-4"> 2. Correcting physical errors through user constraints </h2>
        <div class="content has-text-justified" style="margin-top:-15px; margin-bottom: 30px;">
          <img src="static/images/physical.png" alt="physics" style="margin-bottom:20px">
          <p style="margin-top:5px; margin-bottom: 30px; font-size: 18px;">
            In our approach, we addressed the issue of physically incorrect images generated by the base ARM model by applying Stable Diffusion (SD) inpainting for correction. This method prevents the same physical errors from quickly propagating during subsequent frame. 
            Our findings demonstrate that ACDC effectively mitigates the propagation of physical errors through this correction process.
          </p>
        </div>

        <div class="content has-text-justified" style="margin-bottom: 30px;">
          <img src="static/images/inversion_n_editing_overview.png" alt="t2i_gen_w_interpolation"/>
          <p style="margin-top:5px; font-size: 18px;">
            The figures above compare image editing results using CFG and CFG++ followed by image inversion. 
            During the editing stage, a word in the source text is swapped with the target concept, and this modified text 
            is used as the condition for sampling. Our algorithm successfully works for both synthetic and real images.
          </p>
        </div>
        
        <h2 class="title is-4">3. Autoregressive Video Generation</h2>
        <div class="content has-text-justified">
          <!-- Video Grid -->
          <div class="columns is-multiline is-centered">
            
            <!-- First Row: Prompt 1 -->
            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">LWM</p>
            </div>

            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/3_c.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">ACDC</p>
            </div>


            <!-- Second Row: Prompt 2 -->
            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/2.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">LWM</p>
            </div>

            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/2_c.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">ACDC</p>
            </div>

            <div class="column is-full">
              <p><strong>Prompt 1 & 2:</strong> Description of Prompt 1 and 2 goes here.</p>
            </div>

            <!-- Third Row: Prompt 3 -->
            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/1.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">LWM</p>
            </div>

            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/1_c.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">ACDC</p>
            </div>

            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/1.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">LWM</p>
            </div>

            <div class="column is-one-quarter">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/videos/1_c.mp4" type="video/mp4">
              </video>
              <p style="margin-top: 5px;">ACDC</p>
            </div>

            <div class="column is-full">
              <p><strong>Prompt 1 & 2:</strong> Description of Prompt 1 and 2 goes here.</p>
            </div>

            <!-- Add more prompts and videos as necessary -->

          </div>
          <!-- End Video Grid -->

          <p style="margin-top:5px; margin-bottom: 10px; font-size: 18px;">
            These videos showcase the comparison between our approach and the baseline in generating coherent multi-frame sequences.
          </p>
      </div> 

      </div>
    </div>
  </div>
</section>



<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
